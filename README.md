# Fish_Classification_Recognition_Minor
 
#ğŸŸ Fish Classification and Recognition System
ğŸ“Œ Introduction to the Problem
Estimating the relative abundance of fish species in their habitats and monitoring population fluctuations are crucial for marine scientists and conservationists. Traditionally, this has been done through manual sampling, which is time-consuming and inefficient.

To tackle this, automated computer-based fish sampling has been introduced using underwater images and videos. However, accurate fish detection and classification remain a challenge due to:

ğŸŒŠ Environmental fluctuations (lighting changes, water clarity)

ğŸ  Fish camouflage

ğŸ¥ Dynamic backgrounds

ğŸ–¼ï¸ Low-resolution images

ğŸ”„ Shape deformations of moving fish

ğŸ§ Tiny differences between some species

This project aims to provide an efficient and accurate solution to classify fish species using deep learning. Users can upload an image of a fish and get the predicted species name along with model confidence scores.

ğŸ“‚ Understanding the Dataset
This dataset contains 9 different seafood types for classification:
âœ… Gilt-head bream
âœ… Red sea bream
âœ… Sea bass
âœ… Red mullet
âœ… Horse mackerel
âœ… Black sea sprat
âœ… Striped red mullet
âœ… Trout
âœ… Shrimp

For each class, there are 1000 augmented images and their pair-wise augmented ground truth labels.

ğŸ“Œ Dataset Organization:

All images for each class are stored in the Fish_Dataset folder.

Ground truth labels are stored in a structured format.

Images are ordered from "00000.png" to "01000.png".

ğŸ“Œ Example:
If you want to access the ground truth images of shrimp, the order should be followed as:
Fish -> Shrimp -> Shrimp GT
ğŸ§  Model Information - MobileNetV2 Architecture
We have used MobileNetV2, a lightweight deep learning model, for fish classification.

Why MobileNetV2?
âš¡ Optimized for Mobile & Web â€“ Low computational cost

ğŸ¯ High Accuracy â€“ Uses depthwise separable convolutions

ğŸš€ Efficient & Fast â€“ Works well on low-powered devices

MobileNetV2 Architecture
MobileNetV2 is a convolutional neural network (CNN) architecture designed for efficient classification, particularly on mobile devices. It is based on an inverted residual structure where the residual connections exist between bottleneck layers.

Key Features of MobileNetV2:
âœ… Initial convolution layer with 32 filters
âœ… 19 residual bottleneck layers
âœ… Lightweight depthwise convolutions for feature extraction
âœ… Non-linear activation functions for better classification

This model is pre-trained on large datasets and then fine-tuned on the fish classification dataset for improved accuracy.

ğŸš€ About the Project
Our Fish Classification and Recognition Web App allows users to:
âœ… Upload an image of a fish
âœ… Get the predicted species and confidence score
âœ… View real-time classification results
âœ… Experience a user-friendly interface

We use deep learning models to classify fish species accurately from an input image.

âš™ï¸ Installation & Setup
Ensure you have Python installed, then set up the environment:

bash
Copy
Edit
# Clone the repository
git clone https://github.com/Agam3108/Minor_Project_Fish_Classification.git
cd Minor_Project_Fish_Classification

# Install dependencies
pip install -r requirements.txt
â–¶ï¸ Running the Application
Run the Streamlit web app with:
streamlit run model.py
This will launch the web application in your default browser.

ğŸ“ Usage
1ï¸âƒ£ Open the app in your browser.
2ï¸âƒ£ Upload an image of a fish.
3ï¸âƒ£ Click the Predict button.
4ï¸âƒ£ View the predicted species and confidence score.

Example Output
Predicted Species: Salmon  
Confidence: 95.3%
